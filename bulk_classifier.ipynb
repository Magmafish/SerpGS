{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** FUNCTION SECTION ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FETCH API_KEY FROM FILE\n",
    "\n",
    "def load_api_key(key_name=\"oai_key.txt\", path=\"secret/\"):\n",
    "    global api_key\n",
    "    api_key_path = path + key_name\n",
    "    with open(api_key_path, \"r\") as file:\n",
    "        api_key = file.read()\n",
    "    print(f'api_key loaded as global varible (is type {type(api_key).__name__} and {len(api_key)} characters long)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "api_key loaded as global varible (is type str and 32 characters long)\n"
     ]
    }
   ],
   "source": [
    "# THIS NEED TO BE HERE OR FUNCTIONS WILL ERROR EVEN BEFORE CALLED\n",
    "\n",
    "load_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GET O.AI BALANCE\n",
    "\n",
    "def get_balance(api_key=api_key):\n",
    "    headers={'X-OAI-API-KEY': api_key}\n",
    "    response_1 = requests.get('https://api.originality.ai/api/v1/account/credits/balance',headers=headers)\n",
    "    return(response_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFY 1 WEB PAGE AND RETURN RESPONSE\n",
    "\n",
    "def fetch_url_class(url_in, api_key=api_key): \n",
    "    scan_url='https://api.originality.ai/api/v1/scan/url'\n",
    "    headers={'X-OAI-API-KEY': api_key}\n",
    "    params={\"url\": url_in}\n",
    "    response = requests.post(url=scan_url, headers=headers, params=params)\n",
    "    return(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT AI/HUMAN SCORE FROM 1 RESPONSE AND RETURN DF\n",
    "\n",
    "def extract_score(response):\n",
    "    r_json = response.json()\n",
    "    if r_json['success']:\n",
    "        data = {\n",
    "                'Success': [r_json['success']],\n",
    "                'word_count': [r_json['word_count']],\n",
    "                'Percent_Human': [r_json['score']['original'] * 100],\n",
    "                'Percent_AI': [r_json['score']['ai'] * 100]\n",
    "                # probably shoudn't round yet\n",
    "                #'Percent_Human': [round(r_json['score']['original'] * 100, 1)],\n",
    "                #'Percent_AI': [round(r_json['score']['ai'] * 100, 1)]\n",
    "        }\n",
    "        if len(r_json['score_breakdown']) > 0:\n",
    "            data['text'] = [r_json['score_breakdown'][0]['text']]\n",
    "            \n",
    "        else:\n",
    "            data['text'] = ['']\n",
    "\n",
    "    else:\n",
    "        data = {\n",
    "            'Success': False,\n",
    "            'word_count': None,\n",
    "            'Percent_Human': None,\n",
    "            'Percent_AI': None,\n",
    "            'text': ['']\n",
    "        }\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRICATED\n",
    "\n",
    "# FAILS IF score_breakdown list is empty\n",
    "\n",
    "# def extract_score(response):\n",
    "#     r_json = response.json()\n",
    "#     if r_json['success']:\n",
    "#         data = {\n",
    "#         'Success': [r_json['success']],\n",
    "#         'word_count': [r_json['word_count']],\n",
    "#         'Percent_Human': [round(r_json['score']['original'] * 100, 1)],\n",
    "#         'Percent_AI': [round(r_json['score']['ai'] * 100, 1)],\n",
    "#         'text': [r_json['score_breakdown'][0]['text']]\n",
    "#         }\n",
    "#     else:\n",
    "#         data = {\n",
    "#             'Success': [False],\n",
    "#             'word_count': [None],\n",
    "#             'Percent_Human': [None],\n",
    "#             'Percent_AI': [None],\n",
    "#             'text': ['']\n",
    "#         }\n",
    "#     df = pd.DataFrame(data)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEPRICATED\n",
    "\n",
    "# def extract_score(response):\n",
    "#     r_json = response.json()\n",
    "#     data = {\n",
    "#         'Success': [r_json['success']],\n",
    "#         'Percent_Human': [round(r_json['score']['original'] * 100, 1)],\n",
    "#         'Percent_AI': [round(r_json['score']['ai'] * 100, 1)]\n",
    "#     }\n",
    "#     df = pd.DataFrame(data)\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKES A DF OF KW AND BREAKS IT UP INTO BATCHES OF 100 CSV FILES\n",
    "# ASSUMES THERE ARE NO MORE THAN 20 OF EACH KW\n",
    "\n",
    "def make_csv_batches(df, batch_size=5, output_dir='data/batches'):\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get unique values in the 'kw' column\n",
    "    unique_kw = df['kw'].unique()\n",
    "\n",
    "    # Break up unique values into batches of batch_size\n",
    "    kw_batches = [unique_kw[i:i+batch_size] for i in range(0, len(unique_kw), batch_size)]\n",
    "\n",
    "    # Iterate through kw_batches and create csv files for each batch\n",
    "    filenames = []\n",
    "    for i, batch in enumerate(kw_batches):\n",
    "        # Select rows from df where 'kw' is in the current batch\n",
    "        batch_df = df[df['kw'].isin(batch)]\n",
    "\n",
    "        # Write subset_df to csv\n",
    "        filename = f'kw_batch_{i:03d}.csv'\n",
    "        filepath = os.path.join(output_dir, filename)\n",
    "        batch_df.to_csv(filepath, index=False)\n",
    "        filenames.append(filename)\n",
    "\n",
    "    #Write list of filenames to batch_list.csv\n",
    "    with open(os.path.join(output_dir, 'batch_list.csv'), 'w') as f:\n",
    "        f.write('\\n'.join(filenames))\n",
    "\n",
    "    print(f'{len(kw_batches)} csv files created in {output_dir}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# READS THE FILE CONTAINING BATCH FILENAMES AND RETURNS LIST\n",
    "\n",
    "def read_batch_list(read_path='data/batches'):\n",
    "    batch_list_path = os.path.join(read_path, 'batch_list.csv')\n",
    "    with open(batch_list_path, 'r') as file:\n",
    "        batch_filenames = [line.strip() for line in file]\n",
    "    return batch_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TAKES DF AND APPENDS EACH ROW WITH CLASSIFCATION INFO EXTRACTED FROM RESPONSE\n",
    "\n",
    "def classify_batch(df):\n",
    "    results = []\n",
    "    for url in df['link']:\n",
    "        response = fetch_url_class(url)\n",
    "        if response.status_code == 200:\n",
    "            score_df = extract_score(response)\n",
    "            success = score_df['Success'][0]\n",
    "            word_count = score_df['word_count'][0]\n",
    "            human = score_df['Percent_Human'][0]\n",
    "            ai = score_df['Percent_AI'][0]\n",
    "            # text = score_df['text'][0]\n",
    "            #results.append({'link': url, 'success': success, 'word_count': word_count, 'percent_human': human, 'percent_ai': ai, 'text': text})\n",
    "            results.append({'link': url, 'success': success, 'word_count': word_count, 'percent_human': human, 'percent_ai': ai})\n",
    "            delay = 10 # WHEN PROCESSING ACTUALLY NEEDS TO BE DONE DELAY IS HIGHER\n",
    "        else:\n",
    "            print(f'RC error code: {response.status_code}, URL: {url}')\n",
    "            #results.append({'link': url, 'success': False, 'percent_human': None, 'percent_ai': None, 'text': 'none'})\n",
    "            results.append({'link': url, 'success': False, 'percent_human': None, 'percent_ai': None})\n",
    "            delay = 2 # WHEN NO PROCESSING IS REQUIRED DELAY IS 2\n",
    "        time.sleep(delay)  # wait for 1 second between requests\n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT DOING THIS FOR NOW - TOO MANY FILES TO HANDLE\n",
    "\n",
    "# SAVE RESPONSE FILES\n",
    "\n",
    "#def save_response(response):\n",
    "    \n",
    "#    print('response saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFIES ALL BATCHES\n",
    "\n",
    "def classify_all_batches():\n",
    "    # LOAD CSV PATHS INTO LIST\n",
    "    read_dir = 'data/batches/'\n",
    "    save_dir = 'data/batches_classified'\n",
    "    batches = read_batch_list()\n",
    "    \n",
    "    for batch_name in batches:\n",
    "\n",
    "        # check for sufficent credits\n",
    "        credits = get_balance().json()['balance']\n",
    "        #if balance is not None and json.loads(balance) > 1600:\n",
    "        if credits > 1600:\n",
    "\n",
    "            # START TIMER \n",
    "            # start_time = time.time() # NOT CURRENTLY NEEDED BECAUSE EACH RECORD TAKES MORE THAT A MINUTE TO PROCESS\n",
    "            print(f'Credits = {credits}, Classifying: {batch_name}')\n",
    "\n",
    "            # LOAD CSV BATCH INTO DF\n",
    "            df_in = pd.read_csv(f'{read_dir}{batch_name}', header=0)\n",
    "            \n",
    "            # CLASSIFY BATCH\n",
    "            df_out = classify_batch(df_in)\n",
    "\n",
    "            # CONCAT DFS\n",
    "            df = pd.concat([df_in, df_out], axis=1, join='outer')\n",
    "\n",
    "            # SAVE DF OF CLASSIFIED BATCH\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "            save_path = os.path.join(save_dir, batch_name)\n",
    "            df.to_csv(save_path, index=False)\n",
    "\n",
    "            # WAIT FOR TIMER TO REACH 1 MINUTE\n",
    "            # elapsed_time = time.time() - start_time\n",
    "            # if elapsed_time < 60:\n",
    "            #     time.sleep(60 - elapsed_time)\n",
    "        else:\n",
    "            print(f\"*** INSUFFICENT CREDITS *** YOU HAVE: {credits} CREDITS. GO BEG CONNOR FOR MORE\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduled_batches():\n",
    "    # LOAD CSV PATHS INTO LIST\n",
    "    read_dir = 'data/batches/'\n",
    "    save_dir = 'data/batches_classified'\n",
    "    batches = read_batch_list()\n",
    "    first = batches[0]\n",
    "    last = batches[-1]\n",
    "    count = len(batches)\n",
    "    print(f'There are {count} batches scheduled for processing')\n",
    "    print(f'First scheduled batch: {first}\\nLast scheduled batch: {last}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** EXAMPLES SECTION ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Success</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Percent_Human</th>\n",
       "      <th>Percent_AI</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>303</td>\n",
       "      <td>99.899775</td>\n",
       "      <td>0.100225</td>\n",
       "      <td>A bedroom table lamp sets the mood for your b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Success  word_count  Percent_Human  Percent_AI  \\\n",
       "0     True         303      99.899775    0.100225   \n",
       "\n",
       "                                                text  \n",
       "0   A bedroom table lamp sets the mood for your b...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXAMPLE TO CLASSIFY ONE WEB PAGE AND EXTRACT RESPONSE\n",
    "\n",
    "url_in = \"https://www.target.com/c/table-lamps-lighting-home-decor/-/N-56d7t\"\n",
    "response  = fetch_url_class(url_in)\n",
    "df = extract_score(response)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw</th>\n",
       "      <th>link</th>\n",
       "      <th>Success</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Percent_Human</th>\n",
       "      <th>Percent_AI</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blah</td>\n",
       "      <td>https://www.target.com/c/table-lamps-lighting-...</td>\n",
       "      <td>True</td>\n",
       "      <td>303</td>\n",
       "      <td>99.899775</td>\n",
       "      <td>0.100225</td>\n",
       "      <td>A bedroom table lamp sets the mood for your b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     kw                                               link  Success  \\\n",
       "0  blah  https://www.target.com/c/table-lamps-lighting-...     True   \n",
       "\n",
       "   word_count  Percent_Human  Percent_AI  \\\n",
       "0         303      99.899775    0.100225   \n",
       "\n",
       "                                                text  \n",
       "0   A bedroom table lamp sets the mood for your b...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXAMPLE TO CLASSIFY ONE WEB PAGE AND ADD RESUTLS TO KW AND LINK\n",
    "\n",
    "dfx = pd.DataFrame({'kw': ['blah'], 'link': ['https://www.target.com/c/table-lamps-lighting-home-decor/-/N-56d7t']})\n",
    "url_in = \"https://www.target.com/c/table-lamps-lighting-home-decor/-/N-56d7t\"\n",
    "response  = fetch_url_class(url_in)\n",
    "df = extract_score(response)\n",
    "result = pd.concat([dfx, df], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw</th>\n",
       "      <th>link</th>\n",
       "      <th>Success</th>\n",
       "      <th>word_count</th>\n",
       "      <th>Percent_Human</th>\n",
       "      <th>Percent_AI</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>blah</td>\n",
       "      <td>https://www.target.com/c/table-lamps-lighting-...</td>\n",
       "      <td>True</td>\n",
       "      <td>303</td>\n",
       "      <td>99.899775</td>\n",
       "      <td>0.100225</td>\n",
       "      <td>A bedroom table lamp sets the mood for your b...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     kw                                               link  Success  \\\n",
       "0  blah  https://www.target.com/c/table-lamps-lighting-...     True   \n",
       "\n",
       "   word_count  Percent_Human  Percent_AI  \\\n",
       "0         303      99.899775    0.100225   \n",
       "\n",
       "                                                text  \n",
       "0   A bedroom table lamp sets the mood for your b...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXAMPLE TO CLASSIFY ONE WEB PAGE AND ADD RESUTLS\n",
    "\n",
    "url_in = \"https://www.target.com/c/table-lamps-lighting-home-decor/-/N-56d7t\"\n",
    "response  = fetch_url_class(url_in)\n",
    "df = extract_score(response)\n",
    "result = pd.concat([dfx, df], axis=1)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXAMPLE TO READ IN ONE BATCH AND RUN IT\n",
    "\n",
    "path = 'data/batches/kw_batch_089.csv'\n",
    "dfxxx = pd.read_csv(path, header=0)\n",
    "for link in dfxxx['link']:\n",
    "    df_link = extract_score(fetch_url_class(url))\n",
    "    pd.concat([dfxxx, df_link], axis=1)\n",
    "dfxxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST RUN ONE BATCH AND ADD ALL THE OTHER DEETS\n",
    "\n",
    "df_in = pd.read_csv('data/batches/' + 'kw_batch_000.csv')\n",
    "df_out = classify_batch(dfx)\n",
    "\n",
    "df_out = pd.concat([df_in, df_out], axis=1, join='outer')\n",
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** CODE SECTION *** REALLY THIS IS ALL YOU NEED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153549"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CHECK TO SEE IF ACCOUNT HAS CREDIT AVAILABLE\n",
    "\n",
    "credits = get_balance()\n",
    "credits.json()['balance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOAD KW AND LINK DATA CREATED IN GSEARCH.IPYNB \n",
    "\n",
    "#df = pd.read_csv('data/linked_kw_final.csv', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIVIDE DATA INTO BATCHES OF 100 RECORDS SO THAT WHEN IT FAILS I DON'T NEED TO START FROM BEGINING\n",
    "\n",
    "# make_csv_batches(df_linked_kw_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 91 batches scheduled for processing\n",
      "First scheduled batch: kw_batch_109.csv\n",
      "Last scheduled batch: kw_batch_199.csv\n"
     ]
    }
   ],
   "source": [
    "scheduled_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start saving the response files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credits = 153077, Classifying: kw_batch_109.csv\n"
     ]
    }
   ],
   "source": [
    "# PROCESSES ALL RECORDS IN BATCHES OF 100\n",
    "\n",
    "classify_all_batches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classify_batch(df) should handle connection reset?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b9d0320435b592720051846a30c3c35a68bf649ab9728fd60bade915b8884093"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
