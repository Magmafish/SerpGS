{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Purpose of this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "import matplotlib.cm as cm\n",
    "#from IPython.display import JSON\n",
    "import math\n",
    "import inspect\n",
    "from typing import List, Dict, Optional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_df_info(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Prints information about a DataFrame, including column names, data types, and non-null counts.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame to process.\n",
    "        \n",
    "    Returns:\n",
    "        pandas.DataFrame: A DataFrame containing the column names, data types, and non-null counts, and null counts of the input DataFrame.\n",
    "    \"\"\"\n",
    "    col_names = df.columns.to_list()\n",
    "    col_dtypes = df.dtypes.to_list()\n",
    "    non_null_counts = df.count().to_list()\n",
    "    null_counts = df.isnull().sum().to_list()\n",
    "    info_df = pd.DataFrame({'column_name': col_names, 'dtype': col_dtypes, 'non_null_count': non_null_counts, 'null_count': null_counts})\n",
    "\n",
    "    caller_frame = inspect.currentframe().f_back\n",
    "    df_name = [var_name for var_name, var_val in caller_frame.f_locals.items() if var_val is df][0]\n",
    "\n",
    "    print(f\"DataFrame '{df_name}' has {len(df)} rows and {len(df.columns)} columns.\")\n",
    "    print(\"Here is a summary of the column names, data types and null counts:\")\n",
    "    return info_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_unique_links(df):\n",
    "    #unique_links = df['link'].unique()\n",
    "    unique_links = df['link'].unique().tolist()\n",
    "    return unique_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nonunique_links(df):\n",
    "    #nonunique_links = df[df.duplicated(['link'])]\n",
    "    #nonunique_links = df[df.duplicated(['link'])]['link']\n",
    "    nonunique_links = df[df.duplicated(['link'])]['link'].tolist()\n",
    "    return nonunique_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiplotv_dark(df: pd.DataFrame, filter_col: str = None, fmin: float = None, fmax: float = None) -> None:\n",
    "    \"\"\"\n",
    "    Generate a set of 4 plots to visualize the relationship between two variables in a DataFrame.\n",
    "    :param df: DataFrame containing the data\n",
    "    :param filter_col: Name of the column to filter on (optional)\n",
    "    :param filter_min: Minimum value for the filter_col (optional)\n",
    "    :param filter_max: Maximum value for the filter_col (optional)\n",
    "    \"\"\"\n",
    "\n",
    "    # define subplots\n",
    "    face_color = '0.1'\n",
    "    fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(16, 12), facecolor=face_color)\n",
    "    \n",
    "    # Set background color to black\n",
    "    #plt.style.use('dark_background')\n",
    "\n",
    "    # apply filter and subtitle\n",
    "    if filter_col:\n",
    "        if fmin is not None and fmax is not None:\n",
    "            if fmin < fmax:\n",
    "                fig.text(0.5, 0.94, f'Filtered on {fmin} < {filter_col} < {fmax}', ha='center', fontsize=16, color='white')\n",
    "                df = df[(df[filter_col] <= fmax) & (df[filter_col] >= fmin)]\n",
    "            else:\n",
    "                fmin, fmax = fmax, fmin\n",
    "                fig.text(0.5, 0.94, f'Filtered on {fmin} > {filter_col} > {fmax}', ha='center', fontsize=16, color='white')\n",
    "                df = df[(df[filter_col] >= fmax) | (df[filter_col] <= fmin)]\n",
    "        elif fmin is not None and fmax is None:\n",
    "            fig.text(0.5, 0.94, f'Filtered on {filter_col} > {fmin}', ha='center', fontsize=16, color='white')\n",
    "            df = df[df[filter_col] >= fmin]\n",
    "        elif fmin is None and fmax is not None:\n",
    "            fig.text(0.5, 0.94, f'Filtered on {filter_col} < {fmax}', ha='center', fontsize=16, color='white')\n",
    "            df = df[df[filter_col] <= fmax]\n",
    "        else:\n",
    "            print(f'Warning: you must provide a min and/or max on which to filter on {filter_col} or no filtering will occur')\n",
    "\n",
    "    # apply main title\n",
    "    main_title = f'Correlation Study: Rank vs Percent Human ({len(df)} data points)'\n",
    "    fig.suptitle(main_title, fontsize=20, fontweight='bold', y=.98, color='white')\n",
    "    \n",
    "    \n",
    "    # Fig 1: Q-Q plot [0, 0]\n",
    "    st.probplot(df['percent_human'], dist='norm', plot=axs[0, 0])\n",
    "    axs[0, 0].set_title('Figure 1: Q-Q Plot of Percent Human')\n",
    "    axs[0, 0].set_xlabel('Theoretical quantiles')\n",
    "    axs[0, 0].set_ylabel('Sample quantiles')\n",
    "    axs[0, 0].text(0.02, 0.95, 'Data is not normally distributed\\nand cannot be evaluated using Pearson\\'s method', transform=axs[0, 0].transAxes, fontsize=12, verticalalignment='top', color='white')\n",
    "\n",
    "    \n",
    "    # Fig 2: Histogram [0, 1]\n",
    "    sns.histplot(data=df['percent_human'], kde=False, binwidth=1, color='green', ax=axs[0, 1], edgecolor='grey')\n",
    "    axs[0, 1].set_title('Figure 2: Histogram of Percent Human')\n",
    "    axs[0, 1].set_xlabel('Percent Human')\n",
    "    axs[0, 1].set_ylabel('Count')\n",
    "    axs[0, 1].set_xlim(-5, 105)\n",
    "    axs[0, 1].set_ylim(0, None)\n",
    "    skewness = round(st.skew(df['percent_human']), 2)\n",
    "    axs[0, 1].text(0.02, 0.95, f'Data Skewness {skewness}', transform=axs[0, 1].transAxes, fontsize=12, verticalalignment='top', color='white')\n",
    "    #axs[0, 1].text(0.02, 0.90, f'Over 1/3 of data in top 2%', transform=axs[0, 1].transAxes, fontsize=12, verticalalignment='top', color='black')\n",
    "\n",
    "    \n",
    "    # Fig 3: Violin plot [1, 0]\n",
    "    sns.violinplot(ax=axs[1, 0], data=df, x=\"rank\", y=\"percent_human\", scale=\"count\", inner=\"box\", color=\"#00aa00\", saturation=0.5, cut=0, linewidth=.9)\n",
    "\n",
    "        # plot mean lines\n",
    "    for i, mean in enumerate(df.groupby(\"rank\")[\"percent_human\"].mean()):\n",
    "        axs[1, 0].hlines(mean, i-0.25, i+0.25, linewidth=1, color='#bbbbbb', zorder=100)\n",
    "\n",
    "        # plot median markers\n",
    "    median_markers = df.groupby('rank')['percent_human'].median()\n",
    "    sns.scatterplot(ax=axs[1, 0], x=median_markers.index-1, y=median_markers.values, marker='o', s=20, color='white', edgecolor='black', zorder=100)\n",
    "    \n",
    "    axs[1, 0].set_title('Figure 3: Percent Human vs Rank')\n",
    "    axs[1, 0].set_xlabel('Rank')\n",
    "    axs[1, 0].set_ylabel('Percent Human')\n",
    "\n",
    "   \n",
    "    # Fig 4: Scatter plot [1, 1]\n",
    "    grouped_data = df.groupby('rank')\n",
    "    mean_percent_human = grouped_data['percent_human'].mean().reset_index()\n",
    "    sns.scatterplot(ax=axs[1, 1], data=mean_percent_human, x='rank', y='percent_human',  color='green', edgecolor=None)\n",
    "    sns.regplot(ax=axs[1, 1], data=mean_percent_human, x='rank', y='percent_human', color='green', scatter=False, line_kws={'linestyle':'--'})\n",
    "    axs[1, 1].set_title('Figure 4: Mean Percent Human vs Rank')\n",
    "    axs[1, 1].set_xlabel('Rank')\n",
    "    axs[1, 1].set_ylabel('Mean Percent Human')\n",
    "    axs[1, 1].set_xticks(np.arange(1, 21))\n",
    "    axs[1, 1].legend(handles=axs[1, 1].lines[::len(mean_percent_human)], labels=['Best fit line'], facecolor=face_color, labelcolor='white')\n",
    "    axs[1, 1].text(0.02, 0.05, f'Percent Human is weakly correlated to Rank with a high degree of certainty', transform=axs[1, 1].transAxes, fontsize=10, verticalalignment='top', color='white')\n",
    "\n",
    "        # Calculate correlation coefficients and p-values\n",
    "    pb_corr, pb_pval = st.pointbiserialr(df['rank'], df['percent_human'])\n",
    "    spearman_corr, spearman_pval = st.spearmanr(df['rank'], df['percent_human'])\n",
    "    kendall_tau, kendall_pval = st.kendalltau(df['rank'], df['percent_human'])\n",
    "\n",
    "        # Create a dictionary to store the results\n",
    "    corr = {\n",
    "        'Method': ['Point Biserial', 'Spearman', 'Kendall'],\n",
    "        'Corr Coef': [pb_corr, spearman_corr, kendall_tau],\n",
    "        'P-value': [pb_pval, spearman_pval, kendall_pval]\n",
    "    }\n",
    "\n",
    "        # Create a pandas dataframe from the corr dict\n",
    "    df_corr = pd.DataFrame(corr)\n",
    "\n",
    "        # Create a table to display the correlation coefficients and p-values\n",
    "    table_data = [list(df_corr.columns)] + df_corr.values.tolist()\n",
    "    table = axs[1, 1].table(cellText=table_data,\n",
    "                    colLabels=None,\n",
    "                    cellLoc='center',\n",
    "                    bbox=[0.02, 0.08, 0.5, 0.15],  # x, y, width, height\n",
    "                    cellColours=[[face_color]*3] + [[face_color]*3]*len(df_corr))\n",
    "    table.set_fontsize(10)\n",
    "    for cell in table.get_celld().values():\n",
    "        cell.set_linewidth(0)\n",
    "        cell.set_edgecolor('none')\n",
    "        cell.set_text_props(color='white')\n",
    "\n",
    "\n",
    "        # Format the table to use 4 significant figures\n",
    "    for i in range(1, len(table_data)):\n",
    "        for j in range(1, 3):\n",
    "            cell = table.get_celld()[i, j]\n",
    "            cell_text = cell.get_text().get_text()\n",
    "            cell_text = float(cell_text)\n",
    "            cell_text = f'{cell_text:.4g}'\n",
    "            cell.get_text().set_text(cell_text)\n",
    "            #cell.set_edgecolor('white')\n",
    "    \n",
    "    font_color = '#cccccc'\n",
    "    for ax in axs.flat:\n",
    "        ax.tick_params(axis='x', labelsize=12, colors=font_color)\n",
    "        ax.tick_params(axis='y', labelsize=12, colors=font_color)\n",
    "        ax.set_xlabel(ax.get_xlabel(), fontdict={'fontsize': 14, 'color': font_color})\n",
    "        ax.set_ylabel(ax.get_xlabel(), fontdict={'fontsize': 14, 'color': font_color})\n",
    "        ax.set_title(ax.get_title(), fontdict={'fontsize': 16, 'color': 'white'})\n",
    "        ax.set_facecolor(face_color)\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_edgecolor('white')\n",
    "            #spine.set_linewidth(2)\n",
    "    \n",
    "    # shrink outer margin\n",
    "    fig.subplots_adjust(left=0.05, right=0.95, top=.90, bottom=0.05)\n",
    "   \n",
    "    fig.savefig('figures/Fig_1-4.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_highest_kw_per_link(df, links):\n",
    "    highest_kw_per_link = list()\n",
    "    for link in links:\n",
    "        # Select rows with the given link\n",
    "        link_df = df[df['link'] == link]\n",
    "        # Count the number of occurrences of each 'kw' value\n",
    "        kw_counts = link_df['kw'].value_counts()\n",
    "        # Get the highest 'kw' value, or None if there are no 'kw' values\n",
    "        highest_kw = kw_counts.index[0] if len(kw_counts) > 0 else None\n",
    "        # Append the highest 'kw' value for this link to the output list\n",
    "        highest_kw_per_link.append(highest_kw)\n",
    "    return highest_kw_per_link"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw</th>\n",
       "      <th>rank</th>\n",
       "      <th>link</th>\n",
       "      <th>success</th>\n",
       "      <th>word_count</th>\n",
       "      <th>percent_human</th>\n",
       "      <th>percent_ai</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how to finish concrete</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.familyhandyman.com/project/how-to-...</td>\n",
       "      <td>True</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>99.926081</td>\n",
       "      <td>0.073917</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       kw  rank  \\\n",
       "0  how to finish concrete     1   \n",
       "\n",
       "                                                link  success  word_count  \\\n",
       "0  https://www.familyhandyman.com/project/how-to-...     True      1689.0   \n",
       "\n",
       "   percent_human  percent_ai  \n",
       "0      99.926081    0.073917  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/data_clean.old.csv')\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14637"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['uid'] = df['kw'] + '*' + df['link']\n",
    "#df['uid'] = df.apply(lambda row: f\"{row['kw']}_{row['link']}\", axis=1)\n",
    "#df['uid'] = df.apply(lambda row: f\"{row['kw']}_{row['rank']}_{row['link']}\", axis=1)\n",
    "df['uid'] = df.apply(lambda row: f\"{row['kw']}_{row['link']}\", axis=1)\n",
    "df['uid'] = df['uid'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14371"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['uid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = df[df['uid'].duplicated(keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw</th>\n",
       "      <th>rank</th>\n",
       "      <th>link</th>\n",
       "      <th>success</th>\n",
       "      <th>word_count</th>\n",
       "      <th>percent_human</th>\n",
       "      <th>percent_ai</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>early stage blood clot in foot pictures</td>\n",
       "      <td>9</td>\n",
       "      <td>https://stock.adobe.com/search?k=blood%20clots...</td>\n",
       "      <td>True</td>\n",
       "      <td>231.0</td>\n",
       "      <td>3.062132</td>\n",
       "      <td>96.937871</td>\n",
       "      <td>early stage blood clot in foot pictures_https:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>early stage blood clot in foot pictures</td>\n",
       "      <td>17</td>\n",
       "      <td>https://stock.adobe.com/search?k=blood%20clots...</td>\n",
       "      <td>True</td>\n",
       "      <td>231.0</td>\n",
       "      <td>3.062132</td>\n",
       "      <td>96.937871</td>\n",
       "      <td>early stage blood clot in foot pictures_https:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>diastasis</td>\n",
       "      <td>15</td>\n",
       "      <td>https://www.medicalnewstoday.com/articles/dias...</td>\n",
       "      <td>True</td>\n",
       "      <td>923.0</td>\n",
       "      <td>96.124017</td>\n",
       "      <td>3.875982</td>\n",
       "      <td>diastasis_https://www.medicalnewstoday.com/art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>diastasis</td>\n",
       "      <td>17</td>\n",
       "      <td>https://dianeleephysio.com/education/diastasis...</td>\n",
       "      <td>True</td>\n",
       "      <td>4885.0</td>\n",
       "      <td>97.989366</td>\n",
       "      <td>2.010634</td>\n",
       "      <td>diastasis_https://dianeleephysio.com/education...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>diastasis</td>\n",
       "      <td>18</td>\n",
       "      <td>https://www.medicalnewstoday.com/articles/dias...</td>\n",
       "      <td>True</td>\n",
       "      <td>923.0</td>\n",
       "      <td>96.124017</td>\n",
       "      <td>3.875982</td>\n",
       "      <td>diastasis_https://www.medicalnewstoday.com/art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14590</th>\n",
       "      <td>bilateral pneumonia</td>\n",
       "      <td>18</td>\n",
       "      <td>https://www.cidrap.umn.edu/argentine-officials...</td>\n",
       "      <td>True</td>\n",
       "      <td>636.0</td>\n",
       "      <td>96.696997</td>\n",
       "      <td>3.303000</td>\n",
       "      <td>bilateral pneumonia_https://www.cidrap.umn.edu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14591</th>\n",
       "      <td>bilateral pneumonia</td>\n",
       "      <td>19</td>\n",
       "      <td>https://medlineplus.gov/pneumonia.html</td>\n",
       "      <td>True</td>\n",
       "      <td>515.0</td>\n",
       "      <td>1.570927</td>\n",
       "      <td>98.429072</td>\n",
       "      <td>bilateral pneumonia_https://medlineplus.gov/pn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14592</th>\n",
       "      <td>bilateral pneumonia</td>\n",
       "      <td>20</td>\n",
       "      <td>https://www.cidrap.umn.edu/argentine-officials...</td>\n",
       "      <td>True</td>\n",
       "      <td>636.0</td>\n",
       "      <td>96.696997</td>\n",
       "      <td>3.303000</td>\n",
       "      <td>bilateral pneumonia_https://www.cidrap.umn.edu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14635</th>\n",
       "      <td>ruched midi dress</td>\n",
       "      <td>19</td>\n",
       "      <td>https://www.loft.com/petites/petite-dresses/ca...</td>\n",
       "      <td>True</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>92.680357</td>\n",
       "      <td>7.319643</td>\n",
       "      <td>ruched midi dress_https://www.loft.com/petites...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14636</th>\n",
       "      <td>ruched midi dress</td>\n",
       "      <td>20</td>\n",
       "      <td>https://www.loft.com/petites/petite-dresses/ca...</td>\n",
       "      <td>True</td>\n",
       "      <td>1602.0</td>\n",
       "      <td>92.680357</td>\n",
       "      <td>7.319643</td>\n",
       "      <td>ruched midi dress_https://www.loft.com/petites...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>532 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            kw  rank  \\\n",
       "36     early stage blood clot in foot pictures     9   \n",
       "43     early stage blood clot in foot pictures    17   \n",
       "91                                   diastasis    15   \n",
       "93                                   diastasis    17   \n",
       "94                                   diastasis    18   \n",
       "...                                        ...   ...   \n",
       "14590                      bilateral pneumonia    18   \n",
       "14591                      bilateral pneumonia    19   \n",
       "14592                      bilateral pneumonia    20   \n",
       "14635                        ruched midi dress    19   \n",
       "14636                        ruched midi dress    20   \n",
       "\n",
       "                                                    link  success  word_count  \\\n",
       "36     https://stock.adobe.com/search?k=blood%20clots...     True       231.0   \n",
       "43     https://stock.adobe.com/search?k=blood%20clots...     True       231.0   \n",
       "91     https://www.medicalnewstoday.com/articles/dias...     True       923.0   \n",
       "93     https://dianeleephysio.com/education/diastasis...     True      4885.0   \n",
       "94     https://www.medicalnewstoday.com/articles/dias...     True       923.0   \n",
       "...                                                  ...      ...         ...   \n",
       "14590  https://www.cidrap.umn.edu/argentine-officials...     True       636.0   \n",
       "14591             https://medlineplus.gov/pneumonia.html     True       515.0   \n",
       "14592  https://www.cidrap.umn.edu/argentine-officials...     True       636.0   \n",
       "14635  https://www.loft.com/petites/petite-dresses/ca...     True      1602.0   \n",
       "14636  https://www.loft.com/petites/petite-dresses/ca...     True      1602.0   \n",
       "\n",
       "       percent_human  percent_ai  \\\n",
       "36          3.062132   96.937871   \n",
       "43          3.062132   96.937871   \n",
       "91         96.124017    3.875982   \n",
       "93         97.989366    2.010634   \n",
       "94         96.124017    3.875982   \n",
       "...              ...         ...   \n",
       "14590      96.696997    3.303000   \n",
       "14591       1.570927   98.429072   \n",
       "14592      96.696997    3.303000   \n",
       "14635      92.680357    7.319643   \n",
       "14636      92.680357    7.319643   \n",
       "\n",
       "                                                     uid  \n",
       "36     early stage blood clot in foot pictures_https:...  \n",
       "43     early stage blood clot in foot pictures_https:...  \n",
       "91     diastasis_https://www.medicalnewstoday.com/art...  \n",
       "93     diastasis_https://dianeleephysio.com/education...  \n",
       "94     diastasis_https://www.medicalnewstoday.com/art...  \n",
       "...                                                  ...  \n",
       "14590  bilateral pneumonia_https://www.cidrap.umn.edu...  \n",
       "14591  bilateral pneumonia_https://medlineplus.gov/pn...  \n",
       "14592  bilateral pneumonia_https://www.cidrap.umn.edu...  \n",
       "14635  ruched midi dress_https://www.loft.com/petites...  \n",
       "14636  ruched midi dress_https://www.loft.com/petites...  \n",
       "\n",
       "[532 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how to finish concrete_https://www.familyhandyman.com/project/how-to-finish-concrete/'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['uid'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kw</th>\n",
       "      <th>rank</th>\n",
       "      <th>link</th>\n",
       "      <th>success</th>\n",
       "      <th>word_count</th>\n",
       "      <th>percent_human</th>\n",
       "      <th>percent_ai</th>\n",
       "      <th>uid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>how to finish concrete</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.familyhandyman.com/project/how-to-...</td>\n",
       "      <td>True</td>\n",
       "      <td>1689.0</td>\n",
       "      <td>99.926081</td>\n",
       "      <td>0.073917</td>\n",
       "      <td>how to finish concrete_https://www.familyhandy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       kw  rank  \\\n",
       "0  how to finish concrete     1   \n",
       "\n",
       "                                                link  success  word_count  \\\n",
       "0  https://www.familyhandyman.com/project/how-to-...     True      1689.0   \n",
       "\n",
       "   percent_human  percent_ai  \\\n",
       "0      99.926081    0.073917   \n",
       "\n",
       "                                                 uid  \n",
       "0  how to finish concrete_https://www.familyhandy...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/linked_kw_finalcombined.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m combined_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39mdata/linked_kw_finalcombined.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, header\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m combined_df[\u001b[39m'\u001b[39m\u001b[39mlink\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m combined_df[\u001b[39m'\u001b[39m\u001b[39murl\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m      3\u001b[0m combined_df \u001b[39m=\u001b[39m combined_df\u001b[39m.\u001b[39mdrop([\u001b[39m'\u001b[39m\u001b[39murl\u001b[39m\u001b[39m'\u001b[39m], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/stats/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/stats/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/stats/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniconda3/envs/stats/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/envs/stats/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniconda3/envs/stats/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/envs/stats/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/linked_kw_finalcombined.csv'"
     ]
    }
   ],
   "source": [
    "combined_df = pd.read_csv('data/linked_kw_finalcombined.csv', header=0)\n",
    "combined_df['link'] = combined_df['url']\n",
    "combined_df = combined_df.drop(['url'], axis=1)\n",
    "#combined_df['uid'] = combined_df['kw'] + '*' + combined_df['link']\n",
    "#combined_df['uid'] = combined_df.apply(lambda row: f\"{row['kw']}_{row['rank']}_{row['link']}\", axis=1)\n",
    "combined_df['uid'] = combined_df.apply(lambda row: f\"{row['kw']}_{row['link']}\", axis=1)\n",
    "#combined_df['uid'] = combined_df['uid'].astype(str)\n",
    "combined_df['uid'] = combined_df['uid'].str.strip()\n",
    "#combined_df = combined_df.drop(['kw'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kwf = pd.read_csv('data/linked_kw_final.csv', header=0)\n",
    "len(kwf)\n",
    "kwf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[combined_df['link']=='https://www.amazon.com/Side-Table-Lamps/s?k=Side+Table+Lamps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/webmd.csv')\n",
    "df2 = pd.read_csv('data/thespruce.csv')\n",
    "df3 = pd.read_csv('data/amazon.csv')\n",
    "new = pd.concat([df1, df2, df3])\n",
    "new = new.reset_index(drop=True)\n",
    "new = new.copy(deep=True)\n",
    "drop_columns = ['Current position', 'Current URL inside', 'Updated']\n",
    "new = new.drop(drop_columns, axis=1)\n",
    "new = new.rename(columns={'Current URL': 'url'})\n",
    "new = new.rename(columns={'Keyword': 'kw'})\n",
    "new = new.copy(deep=True)\n",
    "#new['uid'] = new['kw'] + '*' + new['url']\n",
    "#new['uid'] = new.apply(lambda row: f\"{row['kw']}_{row['url']}\", axis=1)\n",
    "#new['uid'] = new.apply(lambda row: f\"{row['kw']}_{row['rank']}_{row['url']}\", axis=1)\n",
    "new['uid'] = new.apply(lambda row: f\"{row['kw']}_{row['url']}\", axis=1)\n",
    "new['uid'] = new['uid'].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['uid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df_info(new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new['uid'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new[new['url']=='https://www.amazon.com/Side-Table-Lamps/s?k=Side+Table+Lamps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new[new['uid']=='side table lamps_https://www.target.com/c/table-lamps-lighting-home-decor/-/N-56d7t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new[new['kw']=='side table lamps']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.merge(left=df, right=new, on='uid', how='outer')\n",
    "#df1 = pd.merge(left=df, right=combined_df, on='uid', how='outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df_info(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#result = df1.loc[df1['kw_x'] == df1['kw_y'], ['uid', 'link_x', 'link_y', 'kw_x', 'kw_y']]\n",
    "result = df1.loc[df1['kw_x'] == df1['kw_y'], ['uid', 'url', 'link', 'kw_x', 'kw_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['uid'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_unique(df, col):\n",
    "    count_dict = {}\n",
    "    for uid in df[col].unique():\n",
    "        count_dict[uid] = df[df[col] == uid][col].count()\n",
    "    # sort the dictionary by value in descending order\n",
    "    sorted_dict = dict(sorted(count_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    return sorted_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uids = count_unique(df, 'uid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uids['trash bin*https://www.vocabulary.com/dictionary/trash%20bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_links = get_unique_links(df)\n",
    "len(unique_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonunique_links = get_nonunique_links(df)\n",
    "len(nonunique_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_links = df[~df['link'].isin(nonunique_links)]\n",
    "len(df_unique_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unique_links.head(10).sort_values(by='link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonunique_links = df[df['link'].isin(nonunique_links)]\n",
    "len(df_nonunique_links)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonunique_links.head(10).sort_values(by='link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_kw = get_highest_kw_per_link(df_nonunique_links, nonunique_links)\n",
    "len(most_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonunique_links_most_kw = df_nonunique_links[df_nonunique_links['link'].isin(most_kw)]\n",
    "len(df_nonunique_links_most_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_unique_links) + len(df_nonunique_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_unique_links) + 580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hi_kw = get_highest_kw_per_link(df, unique_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(hi_kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplotv_dark(df, 'percent_human', 0, 74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplotv_dark(df_unique_links, 'percent_human', 0, 74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplotv_dark(df_nonunique_links, 'percent_human', 0, 74)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiplotv_dark(df_nonunique_links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df_info(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_df_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for row in df, combined_df:\n",
    "#    if df['link']==combined_df['link']:\n",
    "#        print('true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf1 = combined_df[combined_df['link'].isin(df['link'])]\n",
    "cdf1.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf2 = cdf1[cdf1['kw'].isin(df['kw'])]\n",
    "len(cdf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(cdf1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf3 = combined_df[combined_df['kw'].isin(df['kw'])]\n",
    "len(cdf3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf4 = cdf3[cdf3['link'].isin(df['link'])]\n",
    "len(cdf4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_unique(df, 'link')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['link']=='https://www.homepest.com/blog/are-wolf-spiders-poisonous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df['link']=='https://www.homepest.com/blog/are-wolf-spiders-poisonous']['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df[combined_df['link']=='https://www.homepest.com/blog/are-wolf-spiders-poisonous\\n']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new[new['url']=='https://www.homepest.com/blog/are-wolf-spiders-poisonous']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stats",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
